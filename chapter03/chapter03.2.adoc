== 3.2 Logic vs. propensity

The results of Section 3.1 present us with a new question. In finding the probability for red at the kth draw, knowledge of what color was found at some earlier draw is clearly relevant because an earlier draw affects the number Mk of red balls in the urn for the kth draw. Would knowledge of the color for a later draw be relevant? At first glance, it seems that it could not be, because the result of a later draw cannot influence the value of Mk . For example, a well-known exposition of statistical mechanics (Penrose, 1979) takes it as a fundamental axiom that probabilities referring to the present time can depend only on what happened earlier, not on what happens later. The author considers this to be a necessary physical condition of ‘causality’.

Therefore we stress again, as we did in Chapter 1, that inference is concerned with logical connections, which may or may not correspond to causal physical influences. To show why knowledge of later events is relevant to the probabilities of earlier ones, consider an urn which is known (background information B) to contain only one red and one white ball: N = 2, M = 1. Given only this information, the probability for red on the first draw is $$P(R_1|B) = 1/2$$. But then if the robot learns that red occurs on the second draw, it becomes certain that it did not occur on the first:

 $$P(R_1|R_2B) = 0$$. (3.38)

More generally, the product rule gives us

 $$P(R_jR_k|B) = P(R_j|R_kB)P(R_k|B) = P(R_k|R_jB)P(R_j|B)$$. (3.39)

But we have just seen that $$P(R_j|B) = P(R_k|B) = M/N$$ for all j, k, so

 $$P(R_j|R_kB) = P(R_k|R_jB)$$, all j, k. (3.40)

Probability theory tells us that the results of later draws have precisely the same relevance as do the results of earlier ones! Even though performing the later draw does not physically affect the number $$M_k$$ of red balls in the urn at the kth draw, information about the result of a later draw has the same effect on our state of knowledge about what could have been taken on the kth draw, as does information about an earlier one. This is our second nonobvious symmetry.

This result will be quite disconcerting to some schools of thought about the ‘meaning of probability’. Although it is generally recognized that logical implication is not the same as physical causation, nevertheless there is a strong inclination to cling to the idea anyway, by trying to interpret a probability P(A|B) as expressing some kind of partial causal influence of B on A. This is evident not only in the aforementioned work of Penrose, but more strikingly in the ‘propensity’ theory of probability expounded by the philosopher Karl Popper.1

It appears to us that such a relation as (3.40)would be quite inexplicable from a propensity viewpoint, although the simple example (3.38) makes its logical necessity obvious. In any event, the theory of logical inference that we are developing here differs fundamentally, in outlook and in results, from the theory of physical causation envisaged by Penrose and Popper. It is evident that logical inference can be applied in many problems where assumptions of physical causation would not make sense.

This does not mean that we are forbidden to introduce the notion of ‘propensity’ or physical causation; the point is rather that logical inference is applicable and useful whether or not a propensity exists. If such a notion (i.e. that some such propensity exists) is formulated as a well-defined hypothesis, then our form of probability theory can analyze its implications. We shall do this in Section 3.10 below. Also, we can test that hypothesis against alternatives in the light of the evidence, just as we can test any well-defined hypothesis. Indeed, one of the most common and important applications of probability theory is to decide whether there is evidence for a causal influence: is a new medicine more effective, or a new engineering design more reliable? Does a new anticrime law reduce the incidence of crime? Our study of hypothesis testing starts in Chapter 4.

1 In his presentation at the Ninth Colston Symposium, Popper (1957) describes his propensity interpretation as ‘purely objective’ but avoids the expression ‘physical influence’. Instead, he would say that the probability for a particular face in tossing a die is not a physical property of the die (as Cram´er (1946) insisted), but rather is an objective property of the whole experimental arrangement, the die plus the method of tossing. Of course, that the result of the experiment depends on the entire arrangement and procedure is only a truism. It was stressed repeatedly by Niels Bohr in connection with quantum theory, but presumably no scientist from Galileo on has ever doubted it. However, unless Popper really meant ‘physical influence’, his interpretation would seem to be supernatural rather than objective. In a later article (Popper, 1959) he defines the propensity interpretation more completely; now a propensity is held to be ‘objective’ and ‘physically real’ even when applied to the individual trial. In the following we see by mathematical demonstration some of the logical difficulties that result from a propensity interpretation. Popper complains that in quantum theory one oscillates between ‘. . . an objective purely statistical interpretation and a subjective interpretation in terms of our incomplete knowledge’, and thinks that the latter is reprehensible and the propensity interpretation avoids any need for it. He could not possibly be more mistaken. In Chapter 9 we answer this in detail at the conceptual level; obviously, incomplete knowledge is the only working material a scientist has! In Chapter 10 we consider the detailed physics of coin tossing, and see just how the method of tossing affects the results by direct physical influence.

In all the sciences, logical inference is more generally applicable.We agree that physical influences can propagate only forward in time; but logical inferences propagate equally well in either direction. An archaeologist uncovers an artifact that changes his knowledge of events thousands of years ago; were it otherwise, archaeology, geology, and paleontology would be impossible. The reasoning of Sherlock Holmes is also directed to inferring, from presently existing evidence, what events must have transpired in the past. The sounds reaching your ears from a marching band 600 meters distant change your state of knowledge about what the band was playing two seconds earlier. Listening to a Toscanini recording of a Beethoven symphony changes your state of knowledge about the sounds Toscanini elicited from his orchestra many years ago.

As this suggests, and as we shall verify later, a fully adequate theory of nonequilibrium phenomena, such as sound propagation, also requires that backward logical inferences be recognized and used, although they do not express physical causes. The point is that the best inferences we can make about any phenomenon – whether in physics, biology, economics, or any other field – must take into account all the relevant information we have, regardless of whether that information refers to times earlier or later than the phenomenon itself; this ought to be considered a platitude, not a paradox. At the end of this chapter (Exercise 3.6), the reader will have an opportunity to demonstrate this directly, by calculating a backward inference that takes into account a forward causal influence.

More generally, consider a probability distribution $$p(x_1···x_n|B)$$, where xi denotes the result of the ith trial, and could take on not just two values (red or white) but, say, the values $$x_i=(1, 2, ... , k)$$ labeling k different colors. If the probability is invariant under any permutation of the $$x_i$$ , then it depends only on the sample numbers $$(n_1···n_k)$$ denoting how many times the result $$x_i = 1$$ occurs, how many times $$x_i = 2$$ occurs, etc. Such a distribution is called exchangeable; as we shall find later, exchangeable distributions have many interesting mathematical properties and important applications. 

Returning to our urn problem, it is clear already from the fact that the hypergeometric distribution is exchangeable that every draw must have just the same relevance to every other draw, regardless of their time order and regardless of whether they are near or far apart in the sequence. But this is not limited to the hypergeometric distribution; it is true of any exchangeable distribution (i.e. whenever the probability for a sequence of events is independent of their order). So, with a little more thought, these symmetries, so inexplicable from the standpoint of physical causation, become obvious after all as propositions of logic.

Let us calculate this effect quantitatively. Supposing j < k, the proposition $$R_jR_k$$ (red at both draws j and k) is in Boolean algebra the same as

 $$R_j R_k = (R_1 + W_1)···(R_{j−1} + W_{j−1}) R_j (R_{j+1} + W_{j+1})···(R_{k−1} + W_{k−1})R_k$$ , (3.41)

which we could expand in the manner of (3.36) into a logical sum of

 $$2^{j−1} × 2^{k−j−1} = 2^{k−2}$$ (3.42)

propositions, each specifying a full sequence, such as

 $$W_1R_2W_3···R_j···R_k$$ (3.43)

of k results. The probability $$P(R_j R_k |B)$$ is the sum of all their probabilities. But we know that, given B, the probability for any one sequence is independent of the order in which red and white appear. Therefore we can permute each sequence, moving $$R_j$$ to the first position, and $$R_k$$ to the second. That is, we can replace the sequence $$(W_1···R_j···)$$ by $$(R_1 ···W_j ···)$$, etc. Recombining them, we have $$(R_1R_2)$$ followed by every possible result for draws (3, 4, . . . , k). In other words, the probability for $$R_j R_k$$ is the same as that of

 $$R_1R_2(R_3 + W_3) ··· (R_k + W_k ) = R_1R_2$$, (3.44)

and we have

 $$P(R_j R_k |B) = P(R_1R_2|B) = \frac {M(M − 1)} {N(N − 1)}$$ , (3.45)

and likewise

 $$P(W_j R_k |B) = P(W_1R_2|B) = \frac {(N − M)M} {N(N − 1)}$$ . (3.46)

Therefore by the product rule

 $$P(R_k|R_jB)= \frac {P(R_jR_k|B)} {P(R_j|B)}  = \frac {M−1} {N−1}$$ (3.47) 
 $$P(R_k|W_jB) = \frac {p(W_jR_k|B)} {P(R_j|B)} = \frac {M} {N-1} $$  (3.48)

for all j < k. By (3.40), the results (3.47) and (3.48) are true for all j= k.

Since as noted this conclusion appears astonishing to many people, we shall belabor the point by explaining it still another time in different words. The robot knows that the urn originally contained M red balls and (N − M) white ones. Then, learning that an earlier draw gave red, it knows that one less red ball is available for the later draws. The problem becomes the same as if we had started with an urn of (N − 1) balls, of which (M − 1) are red; (3.47) corresponds just to the solution (3.37) adapted to this different problem.

But why is knowing the result of a later draw equally cogent? Because if the robot knows that red will be drawn at any later time, then in effect one of the red balls in the urn must be ‘set aside’ to make this possible. The number of red balls which could have been taken in earlier draws is reduced by one, as a result of having this information. The above example (3.38) is an extreme special case of this, where the conclusion is particularly obvious.
